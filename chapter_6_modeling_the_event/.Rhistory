use_seps = TRUE # use commas
) %>%
tab_header(title = "The Top Ten Words Spoken in Prereform and Postreform Parliament") %>%
tab_style(
style = list(cell_text(weight = "bold")),
locations = cells_row_groups()
) %>%
tab_style( # format the column labels
style = list(
cell_fill(color = "black"),
cell_text(weight = "bold", color = "white")
),
locations = cells_column_labels()
) %>%
tab_style( # format the title
style = list(
cell_fill(color = "lightgray"),
cell_text(weight = "bold")
),
locations = cells_title()
)
# count words per speaker per year
prereform_speakers_wordcount <- prereform_words %>%
filter(suggested_speaker != "") %>%
group_by(suggested_speaker, year) %>%
summarize(wordcount = n()) %>%
ungroup() %>%
mutate(period = "prereform")
postreform_speakers_wordcount <- postreform_words %>%
filter(suggested_speaker != "") %>%
group_by(suggested_speaker, year) %>%
summarize(wordcount = n()) %>%
ungroup() %>%
mutate(period = "postreform")
# glue them together
both_periods_speakers <- rbind(prereform_speakers_wordcount, postreform_speakers_wordcount)
# inspect the data
head(both_periods_speakers)
# take the top speakers by wordcount
words_per_speaker <- both_periods_speakers %>%
group_by(suggested_speaker) %>%
summarize(wordsperspeaker = sum(wordcount))
top_speakers <- words_per_speaker %>%
slice_max(wordsperspeaker,
n = 5)
# inspect the data
top_speakers
# Use counting to investigate how many distinct speakers are in the data, pre and postreform
# How many speakers were there prereform?
prereform_only_speakers <- prereform_speakers_wordcount %>%
select(suggested_speaker) %>%
anti_join(postreform_speakers_wordcount, by = "suggested_speaker") %>%
mutate(class = "prereform only")
# inspect the data
prereform_only_speakers %>%
sample_n(10) %>%
head()
# count the number of speakers in the dataset
nrow(prereform_only_speakers)
# How many speakers were there postreform?
postreform_only_speakers <- postreform_speakers_wordcount %>%
select(suggested_speaker) %>%
anti_join(prereform_speakers_wordcount) %>%
mutate(class = "postreform only")
# inspect the data
head(postreform_only_speakers)
# count the number of speakers in the dataset
nrow(postreform_only_speakers)
nrow(postreform_only_speakers) - nrow(prereform_only_speakers)
# How Many Members of Parliament Spoke Both Prereform and Postreform?
continuous_speakers <- prereform_speakers_wordcount %>%
distinct(suggested_speaker) %>%
inner_join(postreform_speakers_wordcount) %>%
ungroup() %>%
mutate(class = "both periods") %>%
distinct(suggested_speaker, class)
nrow(continuous_speakers)
# Count the number of speakers in each category
# glue together the data from each smaller dataset
all_classes <- rbind(prereform_only_speakers, postreform_only_speakers, continuous_speakers)
# group by period and count the number of speakers
all_classes_count <- all_classes %>%
group_by(class) %>%
summarize(speakercount = n()) %>%
arrange(desc(class))
# tell the computer to put the periods in the correct order
all_classes_count$class <- factor(all_classes_count$class, levels = c("prereform only", "postreform only", "both periods"))
# create a bar chart
ggplot(all_classes_count, aes(x = class, y = speakercount)) +
geom_col((aes(fill = class))) +
scale_fill_grey() +
geom_text(aes(label = paste0(speakercount, " speakers")),
colour = "white",
vjust = 1.5) +
labs(title = "How Many Speakers are in Each Category?", x = "", y = "speakers")
## Using Word Count:
## How much did speakers speak before and after the reform act?
# glue the data together for processing
all_per_speaker_wordcounts <- bind_rows(prereform_speakers_wordcount, postreform_speakers_wordcount) %>%
ungroup()
# create a database of speaker, year, and wordcount
all_speakers_annotated <- all_per_speaker_wordcounts %>%
left_join(all_classes) %>%
filter(!is.na(suggested_speaker)) %>%
ungroup()
# inspect the data
all_speakers_annotated
# find the total wordcount_per_speaker
wordcount_per_speaker <-  all_speakers_annotated %>%
rename(wordcount_per_speaker_per_year = wordcount) %>%
group_by(class, suggested_speaker) %>%
summarize(wordcount_per_speaker = sum(wordcount_per_speaker_per_year))
# find the most prolific n speakers of each period
top_speakers <- wordcount_per_speaker %>%
filter(!is.na(suggested_speaker)) %>%
group_by(class) %>%
arrange(desc(wordcount_per_speaker)) %>%
slice_head(n=5) %>%
mutate(top = TRUE)
#inspect the data
top_speakers
# clean up speaker names
speaker_key <- hansard %>%
select(suggested_speaker) %>%
group_by(suggested_speaker) %>%
sample_n(1)
# inspect the data
speaker_key %>%
filter(str_detect(suggested_speaker, "peel_"))
speakers_w_top_and_speaker_key <- all_speakers_annotated %>%
rename(wordcount_per_speaker_per_year = wordcount) %>%
left_join(top_speakers, by = c("suggested_speaker", "class")) %>%
left_join(speaker_key) %>%
distinct()
#*********** STEPH this process generates multiple entires, which is why i resort to distinct(). do you have a more elegant solution? thanks! JG
#inspect the data
speakers_w_top_and_speaker_key %>%
filter(str_detect(suggested_speaker, "peel_")) %>%
select(suggested_speaker, top, year, wordcount_per_speaker_per_year, class) %>%
head() %>%
kable()
# graph it
library("ggrepel") # load a useful package for labeling a dense plot
ggplot(speakers_w_top_and_speaker_key, aes(x = year, y = wordcount_per_speaker_per_year, color = class, shape = class)) +
geom_jitter( # it's worth replacing the geom_jitter with geom_point here and in the next line to see the stakes of diff representations
size = 3
) +
scale_color_grey(guide = guide_legend()) +
geom_label_repel(data=subset(speakers_w_top_and_speaker_key, top == TRUE),
aes(label=suggested_speaker, color = class)) +
guides(fill = "none", label = "none", size = "none") +
theme(legend.position="bottom") +
labs(title = "How Much Did Speakers Speak",
subtitle = "Before and After the Second Reform Act of 1832?")
prereform_top_words_w_speaker_classifications_tfidf <- prereform_words_w_speaker_classifications_tfidf %>%
filter(!is.na(tf_idf)) %>%  # remove NA scores
group_by(class) %>%
arrange(desc(tf_idf)) %>%
slice_head(n =15) %>%
mutate(word = reorder_within(word, wordsperperiod, class))
prereform_top_words_w_speaker_classifications_tfidf$class <- factor(
prereform_top_words_w_speaker_classifications_tfidf$class,
levels = c("prereform only", "postreform only", "both periods")
)
ggplot(prereform_top_words_w_speaker_classifications_tfidf, aes(
x = word,
y = wordsperperiod,
fill = factor(tf_idf)
)) +
geom_col() +
facet_wrap(~class, scales = "free") +
coord_flip() +
scale_fill_grey() +
scale_x_reordered() +
guides(fill = FALSE) +
labs(
title = "Which Words Are Most Distinctive",
subtitle = "of the prereform only speakers vs those who also spoke after the Reform Act of 1832?",
y = "word count"
)
prereform_words_w_speaker_classifications_tfidf <- prereform_words_w_speaker_classifications_counted %>%
bind_tf_idf(word, class, wordsperperiod) %>%
filter(!is.na(class), !is.na(tf_idf)) %>%     # remove NAs before plotting
select(word, class, wordsperperiod, tf_idf)
prereform_top_words_w_speaker_classifications_tfidf <- prereform_words_w_speaker_classifications_tfidf %>%
group_by(class) %>%
arrange(desc(tf_idf)) %>%
slice_head(n = 15) %>%
mutate(word = reorder_within(word, wordsperperiod, class))
prereform_top_words_w_speaker_classifications_tfidf$class <- factor(
prereform_top_words_w_speaker_classifications_tfidf$class,
levels = c("prereform only", "postreform only", "both periods")
)
ggplot(prereform_top_words_w_speaker_classifications_tfidf, aes(
x = word,
y = wordsperperiod,
fill = factor(tf_idf)
)) +
geom_col() +
facet_wrap(~class, scales = "free") +
coord_flip() +
scale_fill_grey() +
scale_x_reordered() +
guides(fill = FALSE) +
labs(
title = "Which Words Are Most Distinctive",
subtitle = "of the prereform only speakers vs those who also spoke after the Reform Act of 1832?",
y = "word count"
)
# --- Libraries (only those needed here) ---
library(dplyr)
library(stringr)
library(tidytext)
library(ggplot2)
library(forcats)      # for fct_drop
# If you use tidytext's reorder_within/scale_x_reordered:
library(tidytext)
# ---------- Part 1b: Postreform vs Continuous (fixed) ----------
# 0) Deduplicate the class lookup to avoid many-to-many explosions
#    Keep a single row per 'suggested_speaker' (first occurrence wins).
#    If you prefer a different rule, replace with a summarise().
all_classes_dedup <- all_classes %>%
distinct(suggested_speaker, .keep_all = TRUE)
# 1) Clean words
postreform_words_cleaned <- postreform_words %>%
filter(!str_detect(word, "^\\s*[0-9]*\\s*$")) %>%         # remove numbers
anti_join(stop_words, by = "word") %>%                    # remove stopwords
mutate(word = lemmatize_words(word))                      # lemmatize
# 2) Join speaker classes and drop unclassified rows
postreform_words_w_speaker_classifications <- postreform_words_cleaned %>%
left_join(all_classes_dedup, by = "suggested_speaker") %>%
filter(!is.na(class))
# 3) Count tokens per (class, word)
postreform_words_w_speaker_classifications_counted <- postreform_words_w_speaker_classifications %>%
group_by(class, word) %>%
summarize(wordsperperiod = n(), .groups = "drop")
# 4) TF-IDF and keep only finite values
postreform_words_w_speaker_classifications_tfidf <- postreform_words_w_speaker_classifications_counted %>%
bind_tf_idf(word, class, wordsperperiod) %>%
filter(is.finite(tf_idf)) %>%
select(word, class, wordsperperiod, tf_idf)
# 5) Top terms per class (drop empty/unused class levels so no "NA" facet)
postreform_top_words_w_speaker_classifications_tfidf <- postreform_words_w_speaker_classifications_tfidf %>%
group_by(class) %>%
arrange(desc(tf_idf), .by_group = TRUE) %>%
slice_head(n = 15) %>%
ungroup() %>%
mutate(
class = factor(class, levels = c("prereform only", "postreform only", "both periods")),
class = fct_drop(class),
word  = reorder_within(word, wordsperperiod, class)
)
# 6) Plot (use a continuous fill scale for continuous tf_idf)
ggplot(postreform_top_words_w_speaker_classifications_tfidf,
aes(x = word, y = wordsperperiod, fill = tf_idf)) +
geom_col() +
facet_wrap(~ class, scales = "free") +
coord_flip() +
scale_fill_gradient(low = "grey90", high = "black") +  # continuous, fixes the error
scale_x_reordered() +
guides(fill = FALSE) +
labs(
title = "Which Words Are Most Distinctive",
subtitle = "of the postreform only speakers vs those who also spoke before the Reform Act of 1832?",
y = "word count",
x = NULL
)
# Applying Tf-idf with a Different Data Architecture Part 2:
# Measure the most distinctive words of prereform only vs postreform only speakers
words_w_speaker_classifications <- all_words_cleaned %>%
left_join(all_classes, by = "suggested_speaker")
words_w_speaker_classifications_counted <- words_w_speaker_classifications %>%
group_by(class, word) %>%
summarize(wordsperperiod = n())
words_w_speaker_classifications_tfidf <- words_w_speaker_classifications_counted %>%
bind_tf_idf(word, class, wordsperperiod) %>%
select(word, class, wordsperperiod, tf_idf)
top_words_w_speaker_classifications_tfidf <- words_w_speaker_classifications_tfidf %>%
filter(!class == "both periods") %>%
group_by(class) %>%
arrange(desc(tf_idf)) %>%
slice_head(n =15) %>%
mutate(word = reorder_within(word, wordsperperiod, class))
# tell the computer what order to put the periods in
top_words_w_speaker_classifications_tfidf$class <- factor(top_words_w_speaker_classifications_tfidf$class, levels = c("prereform only", "postreform only", "both periods"))
ggplot(top_words_w_speaker_classifications_tfidf, aes(x = word, y= wordsperperiod, fill = factor(tf_idf))) +
geom_col() +
facet_wrap(~class, scales = "free") +
coord_flip() +
scale_fill_grey() +
scale_x_reordered() +
guides(fill = FALSE) +
labs(title = "Which Words Are Most Distinctive",
subtitle = "of the speakers who only spoke before or after the Reform Act of 1832?",
y = "word count")
# Use Basic Counting and a Histogram to Investigate How Many Speakers Spoke at the Maximum and Minimum Amounts
# Part 1: Prereform
prereform_only_speakers_wordcount <- prereform_speakers_wordcount %>%
inner_join(prereform_only_speakers)
hist(prereform_only_speakers_wordcount$wordcount)
ggplot(prereform_only_speakers_wordcount, aes(x = wordcount)) +
#geom_dotplot(binwidth=1000)# +
geom_histogram(binwidth = 1000) +
labs(title = "How many prereform speakers spoke how many words?", x = "words spoken", y= "number of speakers")
# Use Basic Counting and a Histogram to Investigate How Many Speakers Spoke at the Maximum and Minimum Amounts
# Part 2: Postreform
postreform_only_speakers_wordcount <- postreform_speakers_wordcount %>%
inner_join(postreform_only_speakers)
hist(postreform_only_speakers_wordcount$wordcount)
ggplot(postreform_only_speakers_wordcount, aes(x = wordcount)) +
#geom_dotplot(binwidth=1000)# +
geom_histogram(binwidth = 1000) +
labs(title = "How many postreform speakers spoke how many words?", x = "words spoken", y= "number of speakers")
# Applying Tf-idf with a Different Data Architecture Part 3:
# For comparing postreform and prereform speech, does it matter whether we only look at the speakers who spoke a lot?
library("textstem")
major_prereform_speakers <- prereform_only_speakers_wordcount %>%
filter(wordcount >= 10000) # <--- here is the cutoff. Change it and see if the results differ!
major_postreform_speakers <- postreform_only_speakers_wordcount %>%
filter(wordcount >= 10000)
major_speakers <- rbind(major_prereform_speakers, major_postreform_speakers)
top_words_w_speaker_classifications_tfidf <- words_w_speaker_classifications %>%
filter(suggested_speaker %in% major_speakers$suggested_speaker) %>%
group_by(class, word) %>%
summarize(wordsperperiod = n()) %>%
bind_tf_idf(word, class, wordsperperiod) %>%
select(word, class, wordsperperiod, tf_idf) %>%
group_by(class) %>%
arrange(desc(tf_idf)) %>%
slice_head(n = 15) %>%
mutate(word = reorder_within(word, wordsperperiod, class))
# tell the computer what order to put the periods in
top_words_w_speaker_classifications_tfidf$class <- factor(top_words_w_speaker_classifications_tfidf$class, levels = c("prereform only", "postreform only", "both periods"))
ggplot(top_words_w_speaker_classifications_tfidf, aes(x = word, y= wordsperperiod, fill = factor(tf_idf))) +
geom_col() +
facet_wrap(~class, scales = "free") +
coord_flip() +
scale_fill_grey() +
scale_x_reordered() +
guides(fill = FALSE) +
labs(title = "Which Words Are Most Distinctive",
subtitle = "of the speakers who only spoke before or after the Reform Act of 1832?",
y = "word count")
# Applying Tf-idf with a Different Data Architecture Part 4:
# Who were the most distinctive prereform/postreform speakers and their words?
words_w_speaker_classifications_tfidf <- words_w_speaker_classifications %>%
filter(suggested_speaker %in% major_speakers$suggested_speaker) %>%
group_by(class, suggested_speaker, word) %>%
summarize(wordsperspeaker = n()) %>%
bind_tf_idf(word, suggested_speaker, wordsperspeaker) %>%
ungroup() %>%
select(word, suggested_speaker, class, wordsperspeaker, tf_idf)
most_distinctive_speakers <- words_w_speaker_classifications_tfidf %>%
filter(!str_detect(suggested_speaker, "said")) %>%
filter(!str_detect(suggested_speaker, "rose")) %>%
group_by(class, suggested_speaker) %>%
summarize(speaker_distinctiveness = sum(tf_idf), total_words = sum(wordsperspeaker)) %>%
ungroup() %>%
group_by(class) %>%
arrange(desc(speaker_distinctiveness)) %>%
slice_head(n = 5)
# note that some of the total_words counted may be below 7000 as we have eliminated stopwords etc.
most_distinctive_speakers <- words_w_speaker_classifications_tfidf %>%
filter(suggested_speaker %in% most_distinctive_speakers$suggested_speaker) %>%
left_join(words_w_speaker_classifications_tfidf) %>%
left_join(speaker_key) %>%
ungroup() %>%
select(-suggested_speaker)
most_distinctive_speakers_top_words <- most_distinctive_speakers %>%
group_by(class, speaker) %>%
arrange(desc(tf_idf)) %>%
mutate(index_number = row_number()) %>%
slice_head(n=5)
# Applying Tf-idf with a Different Data Architecture Part 4:
# Who were the most distinctive prereform/postreform speakers and their words?
words_w_speaker_classifications_tfidf <- words_w_speaker_classifications %>%
filter(suggested_speaker %in% major_speakers$suggested_speaker) %>%
group_by(class, suggested_speaker, word) %>%
summarize(wordsperspeaker = n()) %>%
bind_tf_idf(word, suggested_speaker, wordsperspeaker) %>%
ungroup() %>%
select(word, suggested_speaker, class, wordsperspeaker, tf_idf)
most_distinctive_speakers <- words_w_speaker_classifications_tfidf %>%
filter(!str_detect(suggested_speaker, "said")) %>%
filter(!str_detect(suggested_speaker, "chancellor")) %>%
filter(!str_detect(suggested_speaker, "rose")) %>%
group_by(class, suggested_speaker) %>%
summarize(speaker_distinctiveness = sum(tf_idf), total_words = sum(wordsperspeaker)) %>%
ungroup() %>%
group_by(class) %>%
arrange(desc(speaker_distinctiveness)) %>%
slice_head(n = 5)
# note that some of the total_words counted may be below 7000 as we have eliminated stopwords etc.
most_distinctive_speakers <- words_w_speaker_classifications_tfidf %>%
filter(suggested_speaker %in% most_distinctive_speakers$suggested_speaker) %>%
left_join(words_w_speaker_classifications_tfidf) %>%
left_join(speaker_key) %>%
ungroup() %>%
select(-suggested_speaker)
most_distinctive_speakers_top_words <- most_distinctive_speakers %>%
group_by(class, suggested_speaker) %>%
arrange(desc(tf_idf)) %>%
mutate(index_number = row_number()) %>%
slice_head(n=5)
rm(hansard, annotated_1820, annotated_1830, annotated_1840)
gc()
# load some data (hansardr version needed)
# dates 1822-1842
library("hansardr")
library("tidyverse")
library("lubridate")
library("kableExtra")
data("hansard_1820")
data("hansard_1830")
data("hansard_1840")
data("debate_metadata_1820")
data("debate_metadata_1830")
data("debate_metadata_1840")
data("speaker_metadata_1820")
data("speaker_metadata_1830")
data("speaker_metadata_1840")
annotated_1820 <- hansard_1820 %>%
left_join(debate_metadata_1820)  %>%
mutate(year = year(speechdate)) %>%
left_join(speaker_metadata_1820) %>%
select(text, year, speechdate, suggested_speaker)
annotated_1830 <- hansard_1830 %>%
left_join(debate_metadata_1830) %>%
mutate(year = year(speechdate))  %>%
left_join(speaker_metadata_1830) %>%
select(text, year, speechdate, suggested_speaker)
annotated_1840 <- hansard_1840 %>%
left_join(debate_metadata_1840) %>%
mutate(year = year(speechdate))  %>%
left_join(speaker_metadata_1840) %>%
select(text, year, speechdate, suggested_speaker)
hansard <- bind_rows(annotated_1820, annotated_1830, annotated_1840)
knitr::opts_chunk$set(echo = TRUE)
# Install reticulate if not already installed
if (!requireNamespace("reticulate", quietly = TRUE)) {
install.packages("reticulate")
}
library(reticulate)
# Install Miniconda (cross-platform)
install_miniconda()
reticulate::install_miniconda(
url = "https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh"
)
gc()
knitr::opts_chunk$set(echo = TRUE)
# load some data (hansardr version needed)
# dates 1822-1842
library("hansardr")
library("tidyverse")
library("lubridate")
data("hansard_1820")
data("hansard_1830")
data("hansard_1840")
data("debate_metadata_1820")
data("debate_metadata_1830")
data("debate_metadata_1840")
data("speaker_metadata_1820")
data("speaker_metadata_1830")
data("speaker_metadata_1840")
annotated_1820 <- hansard_1820 %>%
left_join(debate_metadata_1820)  %>%
mutate(year = year(speechdate)) %>%
left_join(speaker_metadata_1820) %>%
select(text, year, speechdate, suggested_speaker)
annotated_1830 <- hansard_1830 %>%
left_join(debate_metadata_1830) %>%
mutate(year = year(speechdate))  %>%
left_join(speaker_metadata_1830) %>%
select(text, year, speechdate, suggested_speaker)
annotated_1840 <- hansard_1840 %>%
left_join(debate_metadata_1840) %>%
mutate(year = year(speechdate))  %>%
left_join(speaker_metadata_1840) %>%
select(text, year, speechdate, suggested_speaker)
hansard <- bind_rows(annotated_1820, annotated_1830, annotated_1840)
# load some data (hansardr version needed)
# dates 1822-1842
library("hansardr")
library("tidyverse")
library("lubridate")
data("hansard_1820")
data("hansard_1830")
data("hansard_1840")
data("debate_metadata_1820")
data("debate_metadata_1830")
data("debate_metadata_1840")
data("speaker_metadata_1820")
data("speaker_metadata_1830")
data("speaker_metadata_1840")
annotated_1820 <- hansard_1820 %>%
left_join(debate_metadata_1820)  %>%
mutate(year = year(speechdate)) %>%
left_join(speaker_metadata_1820) %>%
select(text, year, speechdate, suggested_speaker)
annotated_1830 <- hansard_1830 %>%
left_join(debate_metadata_1830) %>%
mutate(year = year(speechdate))  %>%
left_join(speaker_metadata_1830) %>%
select(text, year, speechdate, suggested_speaker)
annotated_1840 <- hansard_1840 %>%
left_join(debate_metadata_1840) %>%
mutate(year = year(speechdate))  %>%
left_join(speaker_metadata_1840) %>%
select(text, year, speechdate, suggested_speaker)
hansard <- bind_rows(annotated_1820, annotated_1830, annotated_1840)
rm(hansard, annotated_1820, annotated_1830, annotated_1840)
gc()
